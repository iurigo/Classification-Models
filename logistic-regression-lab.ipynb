{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the admissions data.  Drop missing values, and as we did in the lecture, turn `prestige` into a dummy and drop prestige==4 so that it is the reference level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../datasets/admissions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige_1.0</th>\n",
       "      <th>prestige_2.0</th>\n",
       "      <th>prestige_3.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>3.61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>2.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit    gre   gpa  prestige_1.0  prestige_2.0  prestige_3.0\n",
       "0      0  380.0  3.61             0             0             1\n",
       "1      1  660.0  3.67             0             0             1\n",
       "2      1  800.0  4.00             1             0             0\n",
       "3      1  640.0  3.19             0             0             0\n",
       "4      0  520.0  2.93             0             0             0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_ranks = pd.get_dummies(df[\"prestige\"], prefix=\"prestige\")\n",
    "cols_to_keep = [\"admit\", \"gre\", \"gpa\"]\n",
    "df = df[cols_to_keep].join(dummy_ranks).drop('prestige_4.0', axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using [sklearn](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html), fit the logistic regression to the data, and print the coefficients and the intercept.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "y = df['admit']\n",
    "X = df.drop('admit', axis=1)\n",
    "\n",
    "logreg.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.07018745]\n"
     ]
    }
   ],
   "source": [
    "print logreg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.58889206e-03   1.84630696e-04   1.16761197e+00   5.26947989e-01\n",
      "   -3.80822681e-02]]\n"
     ]
    }
   ],
   "source": [
    "print logreg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did the coefficients match what we saw with statsmodel?  If not, why not?  Look closely at the documentation... what is the default behaviour?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.3857036]\n",
      "[[ 0.00217157  0.78165799  1.51273846  0.85283151  0.18807633]]\n"
     ]
    }
   ],
   "source": [
    "# by default, sklearn adds some regularization.  Removing it below by making C very large.\n",
    "logreg = LogisticRegression(C=10000000000)\n",
    "y = df['admit']\n",
    "X = df.drop('admit', axis=1)\n",
    "\n",
    "logreg.fit(X,y)\n",
    "print logreg.intercept_\n",
    "print logreg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do they match now?  If there's a small difference, why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# logistic regressions are solved by iteratively looking for the optimum solution -- the optimizing \n",
    "# functions may have found slightly different local mimima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a prediction of probability of admission for a student with GRE = 700, GPA = 3.8, prestige level 1.  Interpret your result.\n",
    "\n",
    "*hint*: use the `predict_proba` method... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.35036544,  0.64963456]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.predict_proba(np.array([700, 3.8, 1, 0, 0]).reshape(1,-1))\n",
    "# student predicted to be 65% likely to be admitted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use the `predict` method.  How do you think it is making the predictions?  (how does this relate to `predict_proba`)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/phillippa/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.predict([700, 3.8, 1, 0, 0])\n",
    "#if probability that admit = 1 > 0.5, classified as 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.705360212533 0.022308325047\n"
     ]
    }
   ],
   "source": [
    "# base case\n",
    "scores = cross_val_score(logreg, X, y, cv=5)\n",
    "print scores.mean(), scores.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.705360212533 0.0192217788094\n"
     ]
    }
   ],
   "source": [
    "# lasso\n",
    "lasso_cv = LogisticRegressionCV(Cs=200, penalty='l1', solver='liblinear')\n",
    "lasso_cv.fit(X, y)\n",
    "best_c = lasso_cv.C_[0]\n",
    "lasso = LogisticRegression(penalty='l1', C=best_c)\n",
    "scores = cross_val_score(lasso, X, y, cv=5)\n",
    "print scores.mean(), scores.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.702828566964 0.0264168672227\n"
     ]
    }
   ],
   "source": [
    "# ridge\n",
    "ridge_cv = LogisticRegressionCV(Cs=20, penalty='l2')\n",
    "ridge_cv.fit(X, y)\n",
    "best_c = ridge_cv.C_[0]\n",
    "ridge = LogisticRegression(penalty='l2', C=best_c)\n",
    "scores = cross_val_score(ridge, X, y, cv=5)\n",
    "print scores.mean(), scores.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# not a huge difference!  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
